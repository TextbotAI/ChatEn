'''
Import Keras GPT-2:
'''
!pip install keras-gpt-2

'''
Clone OpenAI GPT-2 and download the 774M model:
'''
!git clone https://github.com/openai/gpt-2
!pip3 install -r gpt-2/requirements.txt
!python3 gpt-2/download_model.py 774M

'''
Load trained model from checkpoint:
'''
import os
from keras_gpt_2 import load_trained_model_from_checkpoint, get_bpe_from_files, generate

model_folder = 'models/774M'
config_path = os.path.join(model_folder, 'hparams.json')
checkpoint_path = os.path.join(model_folder, 'model.ckpt')
encoder_path = os.path.join(model_folder, 'encoder.json')
vocab_path = os.path.join(model_folder, 'vocab.bpe')

print('Load model from checkpoint...')
model = load_trained_model_from_checkpoint(config_path, checkpoint_path)

print('Load BPE from files...')
bpe = get_bpe_from_files(encoder_path, vocab_path)

'''
Generate text:
'''
print('Generate text...')
text = 'Project name: Big California House. How to buy the project for this house?'
output = generate(model, bpe, [text], length=20, top_k=3)

'''
Get output WEs:
'''
from keras.models import Model
import numpy as np

texts = ['Mother cleaned the window.']

intermediate_layer_model219 = Model(inputs=model.input, outputs=model.layers[219].output)

batch_size = len(texts)
encodes = [bpe.encode(text) for text in texts]
text_lens = [len(encode) for encode in encodes]
max_len = max(text_lens)
input_data = [encode + [0] * (max_len - len(encode)) for encode in encodes]

intermediate_output219 = intermediate_layer_model219.predict(np.array(input_data))
ArrayWE219 = intermediate_output219[0] #1024 WEs in 1280-dimensional space.

'''
Get input WEs:
'''
ListWeight = model.layers[1].get_weights()
ListWE = ListWeight[0]
ArrayWE = np.asarray(ListWE)
print(ArrayWE.shape)

'''
Decode WEs to text:
'''
text1 = bpe.decode(np.array(input_data)[0])
